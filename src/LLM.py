import fireworks.client
# import openai
# import whisper
from groq import Groq


def speech_reco(audio_file_path):
    # Set your Groq API key
    client = Groq(api_key="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")   
     
    # Open the audio file
    with open(audio_file_path, "rb") as file:
        # Create a transcription of the audio file
        transcription = client.audio.transcriptions.create(
        file=(audio_file_path, file.read()), # Required audio file
        model="whisper-large-v3-turbo", # Required model to use for transcription
        prompt="try to identify the types of this medical order (is it medication, lab test, imaging studies, vital signs or signs and symptoms)",  # Optional
        response_format="json",  # Optional
        language="en",  # Optional
        temperature=0.0  # Optional
        )
    # Print the transcription text
    print(transcription.text)
    return transcription.text

# def speech_reco(audio_file_path):
#     model = whisper.load_model("medium")  # Change to "tiny", "base", "medium" if needed
#     result = model.transcribe(audio_file_path, language="en")
#     print("speech_reco: ", result["text"])
#     return result["text"]


def llm(raw_text):
    # Set your Fireworks API key
    fireworks.client.api_key = 'fw_3ZU4VK5DeFyD2owucFjKLSGP'

    # Define a prompt to refine the text
    prompt = f"""
    The following text is a raw transcription from an audio file. 
    Please improve it to make it more logical, coherent, and grammatically correct. 
    Do not change the meaning of the text, only refine it for clarity and readability, 
    try to identify the types of this medical order (is it medication, lab test, imaging studies, vital signs or signs and symptoms).
    Return ONLY the refined text. Do NOT include any explanations, notes, or additional text.

    Raw Transcription:
    {raw_text}

    Refined Text:
    """

    # Call the Fireworks DeepSeek API
    try:
        response = fireworks.client.Completion.create(
            model="accounts/fireworks/models/deepseek-v3",  # Use the correct model name
            prompt=prompt,
            max_tokens=1000,  # Adjust based on the length of the text
            temperature=0.3,  # Lower temperature for more deterministic output
        )
        print("Full API Response:", response)  # Print the full response for debugging

        # Extract the refined text
        if response.choices and response.choices[0].text.strip():
            refined_text = response.choices[0].text.strip()
        else:
            print("No text generated by the model. Falling back to raw text.")
            refined_text = raw_text  # Fallback to raw text if no output is generated

        # print("Refined Text:", refined_text)
        return refined_text
    except Exception as e:
        print(f"Error in LLM function: {e}")
        return raw_text  # Fallback to raw text if an error occurs